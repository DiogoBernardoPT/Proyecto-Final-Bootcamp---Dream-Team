{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "dea0f263-b3ed-4e07-bb41-afce259eb58a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ETL imports\n",
    "import requests \n",
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from time import sleep\n",
    "\n",
    "# General \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json          \n",
    "import os\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "84a2b3be-8ef3-44bf-847a-5612f7508db1",
   "metadata": {},
   "outputs": [],
   "source": [
    "opts = Options()\n",
    "opts.add_argument(\"user-agent=Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/113.0.0.0 Safari/537.36\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "0c0aea3e-f93f-4a10-9e11-14c3d0672b68",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome(\n",
    "    service=Service(ChromeDriverManager().install()),\n",
    "    options=opts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ebeab3c-0e88-4e29-83f4-40b353778906",
   "metadata": {},
   "source": [
    "## Creamos una lista con los links de los distritos ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0892b04-7d59-4a34-8933-30e5a1310b19",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Lista de distritos de Barcelona\n",
    "distritos = [\n",
    "    \"Ciutat Vella\",\n",
    "    \"Eixample\",\n",
    "    \"Sants-Montjuïc\",\n",
    "    \"Les Corts\",\n",
    "    \"Sarrià-Sant Gervasi\",\n",
    "    \"Gràcia\",\n",
    "    \"Horta-Guinardó\",\n",
    "    \"Nou Barris\",\n",
    "    \"Sant Andreu\",\n",
    "    \"Sant Martí\"\n",
    "]\n",
    "\n",
    "# Creamos una lista par almacenar enlaces de distritos\n",
    "link_distrito = []\n",
    "\n",
    "# URL base con el formato de Airbnb\n",
    "url_base = \"https://www.airbnb.es/s/{distrito}--Barcelona--España/homes?tab_id=home_tab&refinement_paths%5B%5D=%2Fhomes&monthly_start_date=2024-11-01&monthly_length=3&monthly_end_date=2025-02-01&price_filter_input_type=0&channel=EXPLORE&query={distrito}%2C%20Barcelona%2C%20España&date_picker_type=calendar&source=structured_search_input_header&search_type=autocomplete_click\"\n",
    "\n",
    "# Iterar sobre cada distrito y generar el enlace correspondiente\n",
    "for distrito in distritos:\n",
    "    # Reemplazar espacios por %20 y caracteres especiales\n",
    "    distrito_url = distrito.replace(\" \", \"%20\").replace(\"à\", \"%C3%A0\").replace(\"ç\", \"%C3%A7\").replace(\"í\", \"%C3%AD\")\n",
    "    \n",
    "    # Formatear el enlace con el nombre del distrito\n",
    "    enlace = url_base.format(distrito=distrito_url)\n",
    "\n",
    "    link_distrito.append(enlace)\n",
    "    \n",
    "# Imprimir el número y los enlaces de la lista\n",
    "print(len(link_distrito))\n",
    "link_distrito"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebe671aa-5755-405a-bf40-69a9f23d275d",
   "metadata": {},
   "source": [
    "## Obtenemos los links para hacer el scrapping ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f0a44c2-b0e3-46b7-81f1-3939b151ac81",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Lista vacía para almacenar los links de habitaciones\n",
    "links_to_scrapp = []\n",
    "\n",
    "# Accedemos a las paginas de cada distrito\n",
    "\n",
    "for distrito in link_distrito:\n",
    "    \n",
    "    driver.get(f'{distrito}')\n",
    "\n",
    "    # Pausa\n",
    "    sleep(3)\n",
    "\n",
    "\n",
    "\n",
    "    # Bucle para la paginación y extracción\n",
    "    while True:\n",
    "        try:\n",
    "\n",
    "            sleep(5)\n",
    "            # Obtener el código fuente de la página actual\n",
    "            page_source = driver.page_source\n",
    "            soup = BeautifulSoup(page_source, 'html.parser')\n",
    "\n",
    "            # Extraer todos los enlaces de habitaciones en la página actual\n",
    "            link_habitacion = driver.find_elements(By.TAG_NAME, 'a')\n",
    "    \n",
    "            # Lista de url target\n",
    "            links_target = []\n",
    "\n",
    "            # Recorrer todos los enlaces y filtrar los que contienen '/rooms'\n",
    "            for _ in link_habitacion:\n",
    "                link = _.get_attribute('href')\n",
    "                links_target.append(link)\n",
    "                    \n",
    "\n",
    "            # Eliminar duplicados en la lista de enlaces\n",
    "            links_filtered = set(links_target)\n",
    "            print(len(links_filtered))\n",
    "    \n",
    "            # Añadimos los links en la lista de scrappeo\n",
    "            for url in links_filtered:\n",
    "                if '/rooms/' in url:\n",
    "                    links_to_scrapp.append(url)\n",
    "                    print(f'agregando elemento')\n",
    "\n",
    "            print(f\"Total de links extraídos hasta ahora: {len(links_to_scrapp)}\")\n",
    "    \n",
    "            # Pausa antes de hacer clic en la siguiente página\n",
    "            sleep(7)\n",
    "\n",
    "            # Buscar y hacer clic en el botón de \"Siguiente\"\n",
    "            next_button = driver.find_element(By.CSS_SELECTOR, 'a[aria-label=\"Siguiente\"]')\n",
    "            next_button.click()\n",
    "\n",
    "            print('Siguiente página...')\n",
    "\n",
    "        except Exception as e:\n",
    "            # Si no se puede encontrar el botón de \"Siguiente\", salimos del bucle\n",
    "            print('No se pudo cargar la siguiente página o no hay más páginas.')\n",
    "            print(e)\n",
    "            break\n",
    "\n",
    "# Imprimir la lista final de enlaces\n",
    "print(\"Extracción completa. Total de links:\", len(links_to_scrapp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd718fdb-68f1-4642-b5c6-18d5508c07e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(links_to_scrapp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f90bd30-dee2-4e6a-8d66-33914374ca22",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "links_to_scrapp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddcf1b38-57ab-4daf-bb27-e54731813eae",
   "metadata": {},
   "source": [
    "## Obtener informacion de cada enlace ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09106df6-e599-498c-a27d-109c8189932c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterar sobre cada enlace de propiedad\n",
    "for link in links_to_scrapp:\n",
    "    driver.get(link)  # Acceder a la página de la propiedad\n",
    "    sleep(10)\n",
    "\n",
    "    # Capturar el contenido de la página\n",
    "    page_source = driver.page_source\n",
    "    soup = BeautifulSoup(page_source, 'html.parser')\n",
    "\n",
    "    # Extraer la información deseada\n",
    "    try:\n",
    "        name = soup.find_all('h2', class_='hpipapi')[0].text\n",
    "    except:\n",
    "        name = np.nan\n",
    "\n",
    "    try:\n",
    "        host_name = soup.find_all('div', class_='t1pxe1a4')[0].text\n",
    "    except:\n",
    "        host_name = np.nan\n",
    "\n",
    "    try:\n",
    "        property_type = soup.find_all('span', class_='l1h825yc')[1].text\n",
    "    except:\n",
    "        property_type = np.nan\n",
    "\n",
    "    try:\n",
    "        price_per_night = soup.find_all('span', class_='_11jcbg2')[0].text\n",
    "    except:\n",
    "        price_per_night = np.nan\n",
    "\n",
    "    try:\n",
    "        n_rooms = soup.find_all('li', class_='l7n4lsf')[1].text\n",
    "    except:\n",
    "        n_rooms = np.nan\n",
    "\n",
    "    try:\n",
    "        n_beds = soup.find_all('li', class_='l7n4lsf')[2].text\n",
    "    except:\n",
    "        n_beds = np.nan\n",
    "\n",
    "    try:\n",
    "        n_baths = soup.find_all('li', class_='l7n4lsf')[3].text\n",
    "    except:\n",
    "        n_baths = np.nan\n",
    "\n",
    "    try:\n",
    "        check_in = soup.find_all('div', class_='i1303y2k')[0].text\n",
    "    except:\n",
    "        check_in = np.nan\n",
    "\n",
    "    try:\n",
    "        check_out = soup.find_all('div', class_='i1303y2k')[1].text\n",
    "    except:\n",
    "        check_out = np.nan\n",
    "\n",
    "    try:\n",
    "        cleaning_fee = soup.find_all('span', class_='_1k4xcdh')[1].text\n",
    "    except:\n",
    "        cleaning_fee = np.nan\n",
    "\n",
    "    try:\n",
    "        total_guests = soup.find_all('li', class_='l7n4lsf')[0].text\n",
    "    except:\n",
    "        total_guests = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "534bb75c-464b-4099-9662-e47e80aa9bcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get('https://www.airbnb.es/rooms/1227947729562300326?adults=1&category_tag=Tag%3A8678&children=0&enable_m3_private_room=true&infants=0&pets=0&photo_id=1978992110&search_mode=regular_search&check_in=2024-11-09&check_out=2024-11-14&source_impression_id=p3_1729850651_P3hzJjqnS4Yu7HpK&previous_page_section_name=1000&federated_search_id=fddd1a31-e20d-4e6b-b563-88661ffe2565')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "918ef8d4-65cd-4a92-8912-100279bbc5aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Capturar el contenido de la página\n",
    "page_source = driver.page_source\n",
    "soup = BeautifulSoup(page_source, 'html.parser')\n",
    "\n",
    "# Extraer la información deseada\n",
    "try:\n",
    "    name = soup.find_all('h2', class_='hpipapi')[0].text\n",
    "except:\n",
    "    name = np.nan\n",
    "\n",
    "try:\n",
    "    host_name = soup.find_all('div', class_='t1pxe1a4')[0].text\n",
    "except:\n",
    "    host_name = np.nan\n",
    "\n",
    "try:\n",
    "    property_type = soup.find_all('span', class_='l1h825yc')[1].text\n",
    "except:\n",
    "    property_type = np.nan\n",
    "\n",
    "try:\n",
    "    price_per_night = soup.find_all('span', class_='_11jcbg2')[0].text\n",
    "except:\n",
    "    price_per_night = np.nan\n",
    "\n",
    "try:\n",
    "    n_rooms = soup.find_all('li', class_='l7n4lsf')[1].text\n",
    "except:\n",
    "    n_rooms = np.nan\n",
    "\n",
    "try:\n",
    "    n_beds = soup.find_all('li', class_='l7n4lsf')[2].text\n",
    "except:\n",
    "    n_beds = np.nan\n",
    "\n",
    "try:\n",
    "    n_baths = soup.find_all('li', class_='l7n4lsf')[3].text\n",
    "except:\n",
    "    n_baths = np.nan\n",
    "\n",
    "try:\n",
    "    check_in = soup.find_all('div', class_='i1303y2k')[0].text\n",
    "except:\n",
    "    check_in = np.nan\n",
    "\n",
    "try:\n",
    "    check_out = soup.find_all('div', class_='i1303y2k')[1].text\n",
    "except:\n",
    "    check_out = np.nan\n",
    "\n",
    "try:\n",
    "    cleaning_fee = soup.find_all('span', class_='_1k4xcdh')[1].text\n",
    "except:\n",
    "    cleaning_fee = np.nan\n",
    "\n",
    "try:\n",
    "    total_guests = soup.find_all('li', class_='l7n4lsf')[0].text\n",
    "except:\n",
    "    total_guests = np.nan"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3593d981-ada6-4819-880e-c96e498c055d",
   "metadata": {},
   "source": [
    "## Scrapp de los servicios ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "cb29f643-d2dd-421b-a885-1bcbd21723fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Buscar y hacer clic en el botón de \"Siguiente\"\n",
    "button = driver.find_element(By.XPATH, \"//button[contains(text(), 'Mostrar los')]\")\n",
    "button.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "e3cb87f3-6926-4529-a2ea-bde6f5d99e06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Capturar el contenido de la página\n",
    "page_source = driver.page_source\n",
    "soup = BeautifulSoup(page_source, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de7c5b86-073d-46b9-a092-52bf5b922ccb",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "services = soup.find_all('ul', class_= '_2f5j8p')\n",
    "\n",
    "for s in services:\n",
    "    print(s.text)\n",
    "#services"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e135f60a-4eac-4f0e-b111-083af5ddf5ed",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Selecciona todos los encabezados de secciones (en este caso 'h2')\n",
    "secciones = driver.find_elements(By.CSS_SELECTOR, 'h2')\n",
    "\n",
    "\n",
    "# Itera sobre las secciones y asocia los servicios con cada categoría\n",
    "for seccion in secciones:\n",
    "    titulo = seccion.text\n",
    "    # Encontrar los servicios bajo cada título\n",
    "    servicios = seccion.find_elements(By.XPATH, \"./following-sibling::div[1]//li\")\n",
    "    \n",
    "    print(f\"Sección: {titulo}\")\n",
    "    for servicio in servicios:\n",
    "        print(f\"Servicio: {servicio.text}\")\n",
    "\n",
    "    # Filtrar servicios por tipo\n",
    "for servicio in servicios:\n",
    "    if 'bathroom' in servicio.get_attribute('id'):\n",
    "        print(\"Este es un servicio de baño.\")\n",
    "    elif 'bedroom' in servicio.get_attribute('id'):\n",
    "        print(\"Este es un servicio de dormitorio.\")\n",
    "    # Puedes seguir añadiendo otras categorías\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48c08aba-18bd-4b94-9053-64c94c17c150",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "services = soup.find_all('ul', class_='_2f5j8p')\n",
    "\n",
    "for s in services:\n",
    "    # Usamos la propiedad .text para obtener el contenido y lo limpiamos\n",
    "    servicios = s.text.strip().split(\"\\n\")  # Dividimos por saltos de línea\n",
    "    \n",
    "    # Imprimimos cada servicio por separado\n",
    "    for servicio in servicios:\n",
    "        servicio_limpio = servicio.strip()  # Eliminamos espacios innecesarios\n",
    "        if servicio_limpio:  # Aseguramos que no sea una cadena vacía\n",
    "            print(servicio_limpio)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d7cffd1-8da2-4acd-b141-663988dc12b6",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "services = soup.find_all('ul', class_='_2f5j8p')\n",
    "\n",
    "for s in services:\n",
    "    # Encuentra todos los elementos 'li' dentro de la lista de servicios\n",
    "    servicios = s.find_all('li')\n",
    "    \n",
    "    # Imprime cada servicio individualmente\n",
    "    for servicio in servicios:\n",
    "        print(servicio.text.strip())  # Imprime el texto del servicio, limpiando espacios\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7df12d82-7990-4b3b-947e-f7d71a5500e5",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "# Creamos un diccionario para almacenar los servicios por categoría\n",
    "servicios_por_categoria = defaultdict(list)\n",
    "\n",
    "# Encuentra todas las secciones de servicios\n",
    "secciones = soup.find_all('h2')[11:]  # o el selector adecuado para los encabezados de sección\n",
    "\n",
    "# Iteramos sobre cada sección\n",
    "for seccion in secciones:\n",
    "    # Título de la categoría (por ejemplo, \"Baño\", \"Entretenimiento\", etc.)\n",
    "    categoria = seccion.text.strip()\n",
    "    \n",
    "    # Encuentra la lista de servicios que pertenece a esa categoría\n",
    "    servicios = seccion.find_next('ul').find_all('li')\n",
    "    \n",
    "    # Añadimos los servicios al diccionario bajo la categoría correspondiente\n",
    "    for servicio in servicios:\n",
    "        servicio_limpio = servicio.text.strip()\n",
    "        servicios_por_categoria[categoria].append(servicio_limpio)\n",
    "\n",
    "# Ahora imprimimos los servicios por categoría\n",
    "for categoria, servicios in servicios_por_categoria.items():\n",
    "    print(f\"Categoría: {categoria}\")\n",
    "    for servicio in servicios:\n",
    "        print(f\"  - {servicio}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "025bcd36-ab89-406b-9e80-3d68b6c9e9a4",
   "metadata": {},
   "source": [
    "## Scrapp de los comentarios ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "6b9d123b-93d0-4505-aa3f-6891f73a2cd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get('https://www.airbnb.es/rooms/1227947729562300326?adults=1&category_tag=Tag%3A8678&children=0&enable_m3_private_room=true&infants=0&pets=0&photo_id=1978992110&search_mode=regular_search&check_in=2024-11-09&check_out=2024-11-14&source_impression_id=p3_1729850651_P3hzJjqnS4Yu7HpK&previous_page_section_name=1000&federated_search_id=fddd1a31-e20d-4e6b-b563-88661ffe2565')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "ec379e14-d71e-4c3a-a050-6559e47062a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Boton para hacer click en los comentarios\n",
    "button = driver.find_element(By.CSS_SELECTOR, 'button[data-testid=\"pdp-show-all-reviews-button\"]')\n",
    "button.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "786c47ff-9b19-49b4-805b-6a6b322acf05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Capturar el contenido de la página\n",
    "page_source = driver.page_source\n",
    "soup = BeautifulSoup(page_source, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a82be683-757a-4558-9166-3415bcd61d80",
   "metadata": {},
   "outputs": [],
   "source": [
    "star_rat = driver.find_elements(By.CSS_SELECTOR,  \"div[data-testid='pdp-reviews-modal-scrollable-panel'] div.c5dn5hn.atm_9s_1txwivl.atm_cx_t94yts.dir.dir-ltr span.a8jt5op.atm_3f_idpfg4.atm_7h_hxbz6r.atm_7i_ysn8ba.atm_e2_t94yts.atm_ks_zryt35.atm_l8_idpfg4.atm_mk_stnw88.atm_vv_1q9ccgz.atm_vy_t94yts.dir.dir-ltr\" )\n",
    "star_rat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ec06acb-4809-4464-9665-595872a6305d",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "for _ in star_rat:\n",
    "    print(_.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1aa2783b-ab4b-42b0-a659-eaefb87449b0",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Encuentra todos los spans que contienen comentarios\n",
    "# Asegúrate de que el selector XPath sea el adecuado para tu caso\n",
    "comentarios = driver.find_elements(By.CSS_SELECTOR, \"div[data-testid='pdp-reviews-modal-scrollable-panel'] span.l1h825yc.atm_kd_19r6f69_24z95b.atm_kd_19r6f69_1xbvphn_1oszvuo.dir.dir-ltr\" )  # Ajusta la clase según sea necesario\n",
    "comentarios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef933a4f-eff7-4109-a5dc-08777eb23046",
   "metadata": {},
   "outputs": [],
   "source": [
    "for _ in comentarios:\n",
    "    print(_.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "603a9abe-7e1d-4c2d-bf16-570e27742713",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encuentra todos los spans que contienen comentarios\n",
    "comentarios = driver.find_elements(By.CSS_SELECTOR, \"div[data-testid='pdp-reviews-modal-scrollable-panel'] span.l1h825yc.atm_kd_19r6f69_24z95b.atm_kd_19r6f69_1xbvphn_1oszvuo.dir.dir-ltr\")\n",
    "\n",
    "# Itera sobre cada elemento encontrado y extrae el texto del comentario\n",
    "for i, comentario in enumerate(comentarios):\n",
    "    texto = comentario.text  # Extrae el texto de cada comentario\n",
    "    print(f\"Comentario {i + 1}: {texto}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
