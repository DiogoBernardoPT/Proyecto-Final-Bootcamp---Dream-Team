{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "## **Fase 6 - Machine Learning: Construcción y Evaluación del Modelo Predictivo**\n",
    "*En esta fase, nos centramos en construir un modelo predictivo que sea capaz de estimar con precisión el **precio por noche** de las propiedades. Este paso es crucial para convertir los datos procesados en un conocimiento valioso, ya que nos permitirá hacer predicciones sobre el precio de futuras propiedades a partir de sus características. A través de técnicas de machine learning avanzadas, buscamos encontrar el modelo más eficiente, que no solo sea preciso, sino también interpretativo y generalizable*\n",
    "\n",
    "A lo largo de esta fase, aplicaremos una serie de algoritmos y evaluaremos su rendimiento, seleccionando aquel que mejor se ajuste a nuestras necesidades. Además, dedicaremos tiempo a ajustar los parámetros del modelo para maximizar su capacidad predictiva, asegurando así que sea robusto y confiable.\n",
    "Con este enfoque, buscamos no solo predecir el precio de forma precisa, sino también proporcionar una comprensión profunda de los factores clave que afectan los precios de las propiedades, lo que puede ser útil en la toma de decisiones empresariales y en el desarrollo de futuras investigaciones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# General\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Escaladores\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Train, Test\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Modelos\n",
    "from xgboost import XGBRegressor\n",
    "from lightgbm import LGBMRegressor\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.svm import SVR\n",
    "\n",
    "# Neural Neutworks\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "# Hiperparametrización\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Métricas\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import root_mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:1: SyntaxWarning: invalid escape sequence '\\d'\n",
      "<>:1: SyntaxWarning: invalid escape sequence '\\d'\n",
      "C:\\Users\\diogo\\AppData\\Local\\Temp\\ipykernel_15732\\3088068979.py:1: SyntaxWarning: invalid escape sequence '\\d'\n",
      "  df_encoded = pd.read_csv('data\\df_processed_ML.csv')\n"
     ]
    }
   ],
   "source": [
    "df_encoded = pd.read_csv('data\\df_processed_ML.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prices_per_night</th>\n",
       "      <th>ratings</th>\n",
       "      <th>cleaning_fee</th>\n",
       "      <th>dormitorios</th>\n",
       "      <th>camas</th>\n",
       "      <th>baños</th>\n",
       "      <th>maximum_guests</th>\n",
       "      <th>check_in_hour</th>\n",
       "      <th>check_out_hour</th>\n",
       "      <th>total_hours_checkin</th>\n",
       "      <th>...</th>\n",
       "      <th>dormitorio y lavandería</th>\n",
       "      <th>entretenimiento</th>\n",
       "      <th>exterior</th>\n",
       "      <th>internet y oficina</th>\n",
       "      <th>para familias</th>\n",
       "      <th>privacidad y seguridad</th>\n",
       "      <th>seguridad en el hogar</th>\n",
       "      <th>servicios</th>\n",
       "      <th>habitacion</th>\n",
       "      <th>alojamiento entero</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>115.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>900.0</td>\n",
       "      <td>720.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>...</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>46.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>15.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1020.0</td>\n",
       "      <td>660.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>...</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>47.0</td>\n",
       "      <td>4.66</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>900.0</td>\n",
       "      <td>720.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>...</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>100.0</td>\n",
       "      <td>4.89</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>960.0</td>\n",
       "      <td>720.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>...</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>33.0</td>\n",
       "      <td>4.40</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>900.0</td>\n",
       "      <td>660.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2492</th>\n",
       "      <td>55.0</td>\n",
       "      <td>4.74</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>900.0</td>\n",
       "      <td>660.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>...</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2493</th>\n",
       "      <td>60.0</td>\n",
       "      <td>4.78</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>2.0</td>\n",
       "      <td>900.0</td>\n",
       "      <td>600.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2494</th>\n",
       "      <td>104.0</td>\n",
       "      <td>4.96</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>900.0</td>\n",
       "      <td>720.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>...</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2495</th>\n",
       "      <td>120.0</td>\n",
       "      <td>4.83</td>\n",
       "      <td>50.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>900.0</td>\n",
       "      <td>660.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>...</td>\n",
       "      <td>8.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2496</th>\n",
       "      <td>100.0</td>\n",
       "      <td>4.78</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>960.0</td>\n",
       "      <td>660.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>...</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2497 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      prices_per_night  ratings  cleaning_fee  dormitorios  camas  baños  \\\n",
       "0                115.0     0.00           0.0          1.0    1.0    1.0   \n",
       "1                 46.0     0.00          15.0          1.0    1.0    0.5   \n",
       "2                 47.0     4.66           0.0          1.0    1.0    0.5   \n",
       "3                100.0     4.89          35.0          1.0    1.0    1.0   \n",
       "4                 33.0     4.40           0.0          1.0    1.0    0.5   \n",
       "...                ...      ...           ...          ...    ...    ...   \n",
       "2492              55.0     4.74          10.0          1.0    1.0    0.5   \n",
       "2493              60.0     4.78           0.0          1.0    1.0    0.5   \n",
       "2494             104.0     4.96           0.0          2.0    3.0    2.0   \n",
       "2495             120.0     4.83          50.0          1.0    1.0    1.0   \n",
       "2496             100.0     4.78           0.0          1.0    2.0    1.0   \n",
       "\n",
       "      maximum_guests  check_in_hour  check_out_hour  total_hours_checkin  ...  \\\n",
       "0                2.0          900.0           720.0                  9.0  ...   \n",
       "1                1.0         1020.0           660.0                  7.0  ...   \n",
       "2                1.0          900.0           720.0                  9.0  ...   \n",
       "3                1.0          960.0           720.0                  8.0  ...   \n",
       "4                1.0          900.0           660.0                  9.0  ...   \n",
       "...              ...            ...             ...                  ...  ...   \n",
       "2492             3.0          900.0           660.0                  9.0  ...   \n",
       "2493             2.0          900.0           600.0                  9.0  ...   \n",
       "2494             4.0          900.0           720.0                  9.0  ...   \n",
       "2495             2.0          900.0           660.0                  9.0  ...   \n",
       "2496             4.0          960.0           660.0                  8.0  ...   \n",
       "\n",
       "      dormitorio y lavandería  entretenimiento  exterior  internet y oficina  \\\n",
       "0                         7.0              1.0       2.0                 1.0   \n",
       "1                         6.0              0.0       0.0                 2.0   \n",
       "2                         8.0              1.0       1.0                 1.0   \n",
       "3                        10.0             10.0       3.0                 2.0   \n",
       "4                         4.0              0.0       1.0                 1.0   \n",
       "...                       ...              ...       ...                 ...   \n",
       "2492                      7.0              1.0       0.0                 2.0   \n",
       "2493                      4.0              1.0       0.0                 1.0   \n",
       "2494                      9.0              1.0       0.0                 2.0   \n",
       "2495                      8.0              3.0       3.0                 2.0   \n",
       "2496                      8.0              1.0       1.0                 2.0   \n",
       "\n",
       "      para familias  privacidad y seguridad  seguridad en el hogar  servicios  \\\n",
       "0               0.0                     0.0                    1.0        4.0   \n",
       "1               0.0                     2.0                    0.0        1.0   \n",
       "2               0.0                     1.0                    0.0        5.0   \n",
       "3               2.0                     0.0                    5.0        4.0   \n",
       "4               0.0                     0.0                    3.0        1.0   \n",
       "...             ...                     ...                    ...        ...   \n",
       "2492            0.0                     3.0                    0.0        1.0   \n",
       "2493            0.0                     1.0                    0.0        1.0   \n",
       "2494            0.0                     0.0                    2.0        3.0   \n",
       "2495            0.0                     0.0                    2.0        1.0   \n",
       "2496            1.0                     0.0                    2.0        3.0   \n",
       "\n",
       "      habitacion  alojamiento entero  \n",
       "0            0.0                 0.0  \n",
       "1            1.0                 0.0  \n",
       "2            1.0                 0.0  \n",
       "3            0.0                 0.0  \n",
       "4            1.0                 0.0  \n",
       "...          ...                 ...  \n",
       "2492         1.0                 0.0  \n",
       "2493         1.0                 0.0  \n",
       "2494         0.0                 0.0  \n",
       "2495         0.0                 0.0  \n",
       "2496         0.0                 0.0  \n",
       "\n",
       "[2497 rows x 26 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_encoded"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Train Test Split**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2497, 25) (2497,)\n"
     ]
    }
   ],
   "source": [
    "X = df_encoded.drop(\"prices_per_night\", axis = 1)\n",
    "y = df_encoded[\"prices_per_night\"]\n",
    "print(X.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train: (1997, 25), y_train: (1997,)\n",
      "X_test: (500, 25), y_test: (500,)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 42)\n",
    "\n",
    "print(f\"X_train: {X_train.shape}, y_train: {y_train.shape}\")\n",
    "print(f\"X_test: {X_test.shape}, y_test: {y_test.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Escaladores**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_scaler = MinMaxScaler()\n",
    "X_train = x_scaler.fit_transform(X_train)\n",
    "X_test = x_scaler.transform(X_test)\n",
    "\n",
    "y_scaler = MinMaxScaler()\n",
    "y_train = y_scaler.fit_transform(np.array(y_train).reshape(-1, 1))\n",
    "y_test = y_scaler.transform(np.array(y_test).reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear un DataFrame combinando los datos escalados\n",
    "df_X = pd.DataFrame(\n",
    "    np.vstack([X_train, X_test]), \n",
    "    columns=[f\"X_feature_{i}\" for i in range(X_train.shape[1])]\n",
    ")\n",
    "df_X[\"Set\"] = [\"Train\"] * len(X_train) + [\"Test\"] * len(X_test)\n",
    "\n",
    "df_y = pd.DataFrame(\n",
    "    np.vstack([y_train, y_test]), \n",
    "    columns=[\"y\"]\n",
    ")\n",
    "df_y[\"Set\"] = [\"Train\"] * len(y_train) + [\"Test\"] * len(y_test)\n",
    "\n",
    "# Concatenar las características y las etiquetas\n",
    "df = pd.concat([df_X, df_y[\"y\"]], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear DataFrame \n",
    "Scaler = pd.DataFrame(df)\n",
    "#Creamos el pickle\n",
    "Scaler.to_pickle(\"data/Scaler.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X_feature_0</th>\n",
       "      <th>X_feature_1</th>\n",
       "      <th>X_feature_2</th>\n",
       "      <th>X_feature_3</th>\n",
       "      <th>X_feature_4</th>\n",
       "      <th>X_feature_5</th>\n",
       "      <th>X_feature_6</th>\n",
       "      <th>X_feature_7</th>\n",
       "      <th>X_feature_8</th>\n",
       "      <th>X_feature_9</th>\n",
       "      <th>...</th>\n",
       "      <th>X_feature_17</th>\n",
       "      <th>X_feature_18</th>\n",
       "      <th>X_feature_19</th>\n",
       "      <th>X_feature_20</th>\n",
       "      <th>X_feature_21</th>\n",
       "      <th>X_feature_22</th>\n",
       "      <th>X_feature_23</th>\n",
       "      <th>X_feature_24</th>\n",
       "      <th>Set</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.882</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.761905</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.238095</td>\n",
       "      <td>0.600429</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Train</td>\n",
       "      <td>0.046083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.956</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.565941</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Train</td>\n",
       "      <td>0.055300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.264706</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Train</td>\n",
       "      <td>0.034562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.233333</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Train</td>\n",
       "      <td>0.101382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Train</td>\n",
       "      <td>0.062212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2492</th>\n",
       "      <td>0.942</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.389728</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Test</td>\n",
       "      <td>0.041475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2493</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.205882</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Test</td>\n",
       "      <td>0.025346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2494</th>\n",
       "      <td>1.000</td>\n",
       "      <td>0.041176</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Test</td>\n",
       "      <td>0.078341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2495</th>\n",
       "      <td>0.978</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.619048</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>0.380952</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Test</td>\n",
       "      <td>0.101382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2496</th>\n",
       "      <td>0.938</td>\n",
       "      <td>0.411765</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.681186</td>\n",
       "      <td>...</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Test</td>\n",
       "      <td>0.161290</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2497 rows × 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      X_feature_0  X_feature_1  X_feature_2  X_feature_3  X_feature_4  \\\n",
       "0           0.882     0.000000          0.2     0.000000          0.1   \n",
       "1           0.956     0.000000          0.2     0.000000          0.1   \n",
       "2           0.000     0.264706          0.2     0.000000          0.1   \n",
       "3           0.000     0.000000          0.2     0.066667          0.1   \n",
       "4           0.000     0.000000          0.2     0.000000          0.1   \n",
       "...           ...          ...          ...          ...          ...   \n",
       "2492        0.942     0.000000          0.2     0.000000          0.1   \n",
       "2493        0.000     0.205882          0.2     0.000000          0.1   \n",
       "2494        1.000     0.041176          0.2     0.000000          0.1   \n",
       "2495        0.978     0.000000          0.2     0.000000          0.1   \n",
       "2496        0.938     0.411765          0.2     0.000000          0.2   \n",
       "\n",
       "      X_feature_5  X_feature_6  X_feature_7  X_feature_8  X_feature_9  ...  \\\n",
       "0             0.0     0.761905     0.400000     0.238095     0.600429  ...   \n",
       "1             0.1     0.666667     0.300000     0.333333     0.565941  ...   \n",
       "2             0.0     0.714286     0.300000     0.285714     0.000000  ...   \n",
       "3             0.1     0.714286     0.233333     0.285714     0.000000  ...   \n",
       "4             0.1     0.571429     0.166667     0.428571     0.000000  ...   \n",
       "...           ...          ...          ...          ...          ...  ...   \n",
       "2492          0.0     0.666667     0.300000     0.333333     0.389728  ...   \n",
       "2493          0.1     0.714286     0.200000     0.285714     0.000000  ...   \n",
       "2494          0.0     0.714286     0.200000     0.285714     0.000000  ...   \n",
       "2495          0.1     0.619048     0.300000     0.380952     0.000000  ...   \n",
       "2496          0.1     0.714286     0.200000     0.285714     0.681186  ...   \n",
       "\n",
       "      X_feature_17  X_feature_18  X_feature_19  X_feature_20  X_feature_21  \\\n",
       "0              0.0      0.333333      0.000000      0.166667      0.000000   \n",
       "1              0.0      0.666667      0.000000      0.333333      0.000000   \n",
       "2              0.0      0.333333      0.000000      0.166667      0.000000   \n",
       "3              0.0      0.333333      0.000000      0.333333      0.000000   \n",
       "4              0.0      0.333333      0.000000      0.333333      0.000000   \n",
       "...            ...           ...           ...           ...           ...   \n",
       "2492           0.0      0.666667      0.111111      0.000000      0.333333   \n",
       "2493           0.0      0.333333      0.000000      0.166667      0.000000   \n",
       "2494           0.2      0.666667      0.111111      0.333333      0.000000   \n",
       "2495           0.0      0.333333      0.000000      0.166667      0.000000   \n",
       "2496           0.2      0.333333      0.222222      0.000000      0.166667   \n",
       "\n",
       "      X_feature_22  X_feature_23  X_feature_24    Set         y  \n",
       "0         0.142857           1.0           0.0  Train  0.046083  \n",
       "1         0.285714           1.0           0.0  Train  0.055300  \n",
       "2         0.000000           1.0           0.0  Train  0.034562  \n",
       "3         0.000000           1.0           0.0  Train  0.101382  \n",
       "4         0.000000           1.0           0.0  Train  0.062212  \n",
       "...            ...           ...           ...    ...       ...  \n",
       "2492      0.142857           1.0           0.0   Test  0.041475  \n",
       "2493      0.000000           1.0           0.0   Test  0.025346  \n",
       "2494      0.428571           1.0           0.0   Test  0.078341  \n",
       "2495      0.000000           1.0           0.0   Test  0.101382  \n",
       "2496      0.142857           0.0           0.0   Test  0.161290  \n",
       "\n",
       "[2497 rows x 27 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Scaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Selección de los Modelos**\n",
    "- Evaluaremos cada modelo mediante las **métricas de rendimiento**, tales como el **Error Cuadrático Medio (RMSE)** y el **R^2**, con el fin de seleccionar el que brinde el mejor rendimiento predictivo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definimos los modelos\n",
    "models = {\n",
    "    \"Linear Regression\": LinearRegression(),\n",
    "    \"Random Forest\": RandomForestRegressor(random_state=42),\n",
    "    \"Support Vector Regressor\": SVR(),\n",
    "    \"Gradient Boosting\": GradientBoostingRegressor(random_state=42),\n",
    "    \"XGBoost\": XGBRegressor(random_state=42),\n",
    "    \"LightGBM\": LGBMRegressor(random_state=42),\n",
    "    \"MLP Regressor\": MLPRegressor(random_state=42)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000126 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 582\n",
      "[LightGBM] [Info] Number of data points in the train set: 1997, number of used features: 24\n",
      "[LightGBM] [Info] Start training from score 0.143845\n"
     ]
    }
   ],
   "source": [
    "# Lista para almacenar los resultados\n",
    "resultados_lista = []\n",
    "\n",
    "# Bucle para entrenar cada modelo y calcular métricas\n",
    "for model_name, model in models.items():\n",
    "    model.fit(X_train, y_train.ravel())\n",
    "    \n",
    "    y_hat = model.predict(X_test)\n",
    "    \n",
    "    # Desescalado de las predicciones\n",
    "    y_test_inv = y_scaler.inverse_transform(y_test.reshape(-1, 1)).ravel()\n",
    "    y_hat_inv = y_scaler.inverse_transform(y_hat.reshape(-1, 1)).ravel()\n",
    "    \n",
    "    # Cálculo de métricas\n",
    "    mae = mean_absolute_error(y_test_inv, y_hat_inv)\n",
    "    mse = mean_squared_error(y_test_inv, y_hat_inv)\n",
    "    rmse = root_mean_squared_error(y_test_inv, y_hat_inv)\n",
    "    r2 = r2_score(y_test_inv, y_hat_inv)\n",
    "    \n",
    "    # Almacenar resultados\n",
    "    resultados_lista.append({\n",
    "        \"model_name\": model_name,\n",
    "        \"mae\": mae,\n",
    "        \"mse\": mse,\n",
    "        \"rmse\" : rmse,\n",
    "        \"r2_score\": r2\n",
    "    })\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear DataFrame y ordenar por r2_score\n",
    "resultados = pd.DataFrame(resultados_lista)\n",
    "resultados = resultados.sort_values(by=\"r2_score\", ascending=False)\n",
    "#Creamos el pickle\n",
    "resultados.to_pickle(\"data/resultados_modelos.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_name</th>\n",
       "      <th>mae</th>\n",
       "      <th>mse</th>\n",
       "      <th>rmse</th>\n",
       "      <th>r2_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>LightGBM</td>\n",
       "      <td>9.727440</td>\n",
       "      <td>244.834744</td>\n",
       "      <td>15.647196</td>\n",
       "      <td>0.860073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>8.654486</td>\n",
       "      <td>265.400936</td>\n",
       "      <td>16.291131</td>\n",
       "      <td>0.848319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>8.297636</td>\n",
       "      <td>292.500981</td>\n",
       "      <td>17.102660</td>\n",
       "      <td>0.832831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Gradient Boosting</td>\n",
       "      <td>13.716214</td>\n",
       "      <td>376.139506</td>\n",
       "      <td>19.394316</td>\n",
       "      <td>0.785031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Linear Regression</td>\n",
       "      <td>17.901984</td>\n",
       "      <td>615.842171</td>\n",
       "      <td>24.816168</td>\n",
       "      <td>0.648037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>MLP Regressor</td>\n",
       "      <td>19.023449</td>\n",
       "      <td>636.524040</td>\n",
       "      <td>25.229428</td>\n",
       "      <td>0.636217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Support Vector Regressor</td>\n",
       "      <td>20.278318</td>\n",
       "      <td>652.793475</td>\n",
       "      <td>25.549823</td>\n",
       "      <td>0.626919</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 model_name        mae         mse       rmse  r2_score\n",
       "5                  LightGBM   9.727440  244.834744  15.647196  0.860073\n",
       "1             Random Forest   8.654486  265.400936  16.291131  0.848319\n",
       "4                   XGBoost   8.297636  292.500981  17.102660  0.832831\n",
       "3         Gradient Boosting  13.716214  376.139506  19.394316  0.785031\n",
       "0         Linear Regression  17.901984  615.842171  24.816168  0.648037\n",
       "6             MLP Regressor  19.023449  636.524040  25.229428  0.636217\n",
       "2  Support Vector Regressor  20.278318  652.793475  25.549823  0.626919"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resultados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ajuste de Hiperparámetros**\n",
    "   - Para maximizar el rendimiento del modelo, ajustaremos los hiperparámetros clave utilizando **Grid Search**. Este paso es crucial para obtener el mejor modelo posible para nuestros datos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgb = LGBMRegressor(random_state=42) # Quizas el objective se pone aquí\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 500, 1000],\n",
    "    'num_leaves': [31, 63, 127],\n",
    "    'max_depth': [5, 7, 10],\n",
    "    'learning_rate': [0.01, 0.05, 0.1],\n",
    "    'min_child_samples': [20, 50],\n",
    "    'subsample': [0.7, 0.8],\n",
    "    'reg_lambda': [0, 1],\n",
    "    'reg_alpha': [0, 1],\n",
    "    'boosting_type': ['gbdt', 'dart'],\n",
    "    'objective': ['regression']\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search = GridSearchCV(estimator=lgb, param_grid=param_grid, \n",
    "                           scoring='neg_mean_absolute_error', cv=3, \n",
    "                           verbose=1, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 2592 candidates, totalling 7776 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\diogo\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\utils\\validation.py:1339: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000850 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 582\n",
      "[LightGBM] [Info] Number of data points in the train set: 1997, number of used features: 24\n",
      "[LightGBM] [Info] Start training from score 0.143845\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Mejores hiperparámetros: {'boosting_type': 'gbdt', 'learning_rate': 0.1, 'max_depth': 10, 'min_child_samples': 20, 'n_estimators': 1000, 'num_leaves': 31, 'objective': 'regression', 'reg_alpha': 0, 'reg_lambda': 0, 'subsample': 0.7}\n",
      "MAE: 0.016778357053656913\n",
      "MSE: 0.0012209482815996606\n",
      "RMSE 0.03494207036796275\n",
      "R²: 0.8685670597469859\n",
      "CPU times: total: 41.8 s\n",
      "Wall time: 1h 8min 41s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "grid_search.fit(X_train, y_train)\n",
    "# Mostramos los mejores parámetros y resultados\n",
    "best_params = grid_search.best_params_\n",
    "print(\"Mejores hiperparámetros:\", best_params)\n",
    "\n",
    "# comprobamos los  mejores parámetros\n",
    "best_model = grid_search.best_estimator_\n",
    "y_pred = best_model.predict(X_test)\n",
    "\n",
    "# Calculamos y mostramos las métricas\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "rmse = root_mean_squared_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "print(\"MAE:\", mae)\n",
    "print(\"MSE:\", mse)\n",
    "print(\"RMSE\", rmse)\n",
    "print(\"R²:\", r2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creación del pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creamos un diccionario con los resultados\n",
    "grid_search = {\n",
    "    \"best_params\": best_params,\n",
    "    \"mae\": mae,\n",
    "    \"mse\": mse,\n",
    "    \"rmse\": rmse,\n",
    "    \"r2_score\": r2\n",
    "}\n",
    "\n",
    "grid_search = pd.DataFrame(grid_search)\n",
    "grid_search = grid_search.sort_values(by=\"r2_score\", ascending=False)\n",
    "#Creamos el pickle\n",
    "grid_search.to_pickle(\"data/resultados_gridsearch.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>best_params</th>\n",
       "      <th>mae</th>\n",
       "      <th>mse</th>\n",
       "      <th>rmse</th>\n",
       "      <th>r2_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>boosting_type</th>\n",
       "      <td>gbdt</td>\n",
       "      <td>0.016778</td>\n",
       "      <td>0.001221</td>\n",
       "      <td>0.034942</td>\n",
       "      <td>0.868567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>learning_rate</th>\n",
       "      <td>0.1</td>\n",
       "      <td>0.016778</td>\n",
       "      <td>0.001221</td>\n",
       "      <td>0.034942</td>\n",
       "      <td>0.868567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max_depth</th>\n",
       "      <td>10</td>\n",
       "      <td>0.016778</td>\n",
       "      <td>0.001221</td>\n",
       "      <td>0.034942</td>\n",
       "      <td>0.868567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min_child_samples</th>\n",
       "      <td>20</td>\n",
       "      <td>0.016778</td>\n",
       "      <td>0.001221</td>\n",
       "      <td>0.034942</td>\n",
       "      <td>0.868567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>n_estimators</th>\n",
       "      <td>1000</td>\n",
       "      <td>0.016778</td>\n",
       "      <td>0.001221</td>\n",
       "      <td>0.034942</td>\n",
       "      <td>0.868567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>num_leaves</th>\n",
       "      <td>31</td>\n",
       "      <td>0.016778</td>\n",
       "      <td>0.001221</td>\n",
       "      <td>0.034942</td>\n",
       "      <td>0.868567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>objective</th>\n",
       "      <td>regression</td>\n",
       "      <td>0.016778</td>\n",
       "      <td>0.001221</td>\n",
       "      <td>0.034942</td>\n",
       "      <td>0.868567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>reg_alpha</th>\n",
       "      <td>0</td>\n",
       "      <td>0.016778</td>\n",
       "      <td>0.001221</td>\n",
       "      <td>0.034942</td>\n",
       "      <td>0.868567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>reg_lambda</th>\n",
       "      <td>0</td>\n",
       "      <td>0.016778</td>\n",
       "      <td>0.001221</td>\n",
       "      <td>0.034942</td>\n",
       "      <td>0.868567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>subsample</th>\n",
       "      <td>0.7</td>\n",
       "      <td>0.016778</td>\n",
       "      <td>0.001221</td>\n",
       "      <td>0.034942</td>\n",
       "      <td>0.868567</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  best_params       mae       mse      rmse  r2_score\n",
       "boosting_type            gbdt  0.016778  0.001221  0.034942  0.868567\n",
       "learning_rate             0.1  0.016778  0.001221  0.034942  0.868567\n",
       "max_depth                  10  0.016778  0.001221  0.034942  0.868567\n",
       "min_child_samples          20  0.016778  0.001221  0.034942  0.868567\n",
       "n_estimators             1000  0.016778  0.001221  0.034942  0.868567\n",
       "num_leaves                 31  0.016778  0.001221  0.034942  0.868567\n",
       "objective          regression  0.016778  0.001221  0.034942  0.868567\n",
       "reg_alpha                   0  0.016778  0.001221  0.034942  0.868567\n",
       "reg_lambda                  0  0.016778  0.001221  0.034942  0.868567\n",
       "subsample                 0.7  0.016778  0.001221  0.034942  0.868567"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Neural Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar los dados escalados en el ultimo modelo\n",
    "df = pd.read_pickle(\"data/Scaler.pkl\")\n",
    "\n",
    "# Filtrar os dados de treino e teste\n",
    "X_train = df[df['Set'] == 'Train'].drop(columns=['y', 'Set'])\n",
    "X_test = df[df['Set'] == 'Test'].drop(columns=['y', 'Set'])\n",
    "y_train = df[df['Set'] == 'Train']['y']\n",
    "y_test = df[df['Set'] == 'Test']['y']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\diogo\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "\n",
    "# Camada de entrada\n",
    "model.add(Dense(units=64, activation='relu', input_dim=X_train.shape[1]))\n",
    "\n",
    "# Camadas ocultas\n",
    "model.add(Dense(units=32, activation='relu'))\n",
    "model.add(Dense(units=16, activation='relu'))\n",
    "\n",
    "# Camada de saída\n",
    "model.add(Dense(units=1))  # Apenas una salida para el precio\n",
    "\n",
    "model.compile(optimizer=Adam(learning_rate=0.001), loss='mean_squared_error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 0.0158 - val_loss: 0.0041\n",
      "Epoch 2/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0051 - val_loss: 0.0035\n",
      "Epoch 3/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0046 - val_loss: 0.0033\n",
      "Epoch 4/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0037 - val_loss: 0.0032\n",
      "Epoch 5/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0035 - val_loss: 0.0029\n",
      "Epoch 6/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0033 - val_loss: 0.0029\n",
      "Epoch 7/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0031 - val_loss: 0.0028\n",
      "Epoch 8/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0028 - val_loss: 0.0028\n",
      "Epoch 9/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0027 - val_loss: 0.0028\n",
      "Epoch 10/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0026 - val_loss: 0.0026\n",
      "Epoch 11/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0034 - val_loss: 0.0025\n",
      "Epoch 12/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0026 - val_loss: 0.0025\n",
      "Epoch 13/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0021 - val_loss: 0.0025\n",
      "Epoch 14/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0021 - val_loss: 0.0024\n",
      "Epoch 15/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0022 - val_loss: 0.0025\n",
      "Epoch 16/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0021 - val_loss: 0.0024\n",
      "Epoch 17/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0021 - val_loss: 0.0024\n",
      "Epoch 18/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0021 - val_loss: 0.0023\n",
      "Epoch 19/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0019 - val_loss: 0.0023\n",
      "Epoch 20/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0018 - val_loss: 0.0023\n",
      "Epoch 21/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0019 - val_loss: 0.0023\n",
      "Epoch 22/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0020 - val_loss: 0.0022\n",
      "Epoch 23/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0018 - val_loss: 0.0024\n",
      "Epoch 24/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0017 - val_loss: 0.0024\n",
      "Epoch 25/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0019 - val_loss: 0.0023\n",
      "Epoch 26/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0016 - val_loss: 0.0027\n",
      "Epoch 27/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0019 - val_loss: 0.0022\n",
      "Epoch 28/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0019 - val_loss: 0.0023\n",
      "Epoch 29/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0015 - val_loss: 0.0022\n",
      "Epoch 30/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0015 - val_loss: 0.0022\n",
      "Epoch 31/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0015 - val_loss: 0.0024\n",
      "Epoch 32/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0017 - val_loss: 0.0023\n",
      "Epoch 33/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0016 - val_loss: 0.0021\n",
      "Epoch 34/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0015 - val_loss: 0.0023\n",
      "Epoch 35/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0014 - val_loss: 0.0022\n",
      "Epoch 36/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0014 - val_loss: 0.0026\n",
      "Epoch 37/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0013 - val_loss: 0.0023\n",
      "Epoch 38/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0014 - val_loss: 0.0025\n",
      "Epoch 39/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0013 - val_loss: 0.0022\n",
      "Epoch 40/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0013 - val_loss: 0.0023\n",
      "Epoch 41/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0011 - val_loss: 0.0024\n",
      "Epoch 42/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0016 - val_loss: 0.0022\n",
      "Epoch 43/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0012 - val_loss: 0.0021\n",
      "Epoch 44/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0012 - val_loss: 0.0021\n",
      "Epoch 45/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0011 - val_loss: 0.0021\n",
      "Epoch 46/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0013 - val_loss: 0.0021\n",
      "Epoch 47/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0012 - val_loss: 0.0020\n",
      "Epoch 48/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0011 - val_loss: 0.0023\n",
      "Epoch 49/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 9.9960e-04 - val_loss: 0.0021\n",
      "Epoch 50/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 9.9906e-04 - val_loss: 0.0020\n",
      "Epoch 51/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 9.3593e-04 - val_loss: 0.0020\n",
      "Epoch 52/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0011 - val_loss: 0.0020\n",
      "Epoch 53/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0012 - val_loss: 0.0021\n",
      "Epoch 54/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0012 - val_loss: 0.0021\n",
      "Epoch 55/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0011 - val_loss: 0.0021\n",
      "Epoch 56/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0012 - val_loss: 0.0021\n",
      "Epoch 57/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0010 - val_loss: 0.0021\n",
      "Epoch 58/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 8.1344e-04 - val_loss: 0.0019\n",
      "Epoch 59/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0011 - val_loss: 0.0021\n",
      "Epoch 60/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 9.5597e-04 - val_loss: 0.0021\n",
      "Epoch 61/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 9.2757e-04 - val_loss: 0.0019\n",
      "Epoch 62/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 8.8808e-04 - val_loss: 0.0020\n",
      "Epoch 63/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 9.5219e-04 - val_loss: 0.0022\n",
      "Epoch 64/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0011 - val_loss: 0.0021\n",
      "Epoch 65/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 9.0015e-04 - val_loss: 0.0019\n",
      "Epoch 66/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 7.5997e-04 - val_loss: 0.0020\n",
      "Epoch 67/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 9.2917e-04 - val_loss: 0.0019\n",
      "Epoch 68/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 8.2548e-04 - val_loss: 0.0020\n",
      "Epoch 69/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 7.9024e-04 - val_loss: 0.0021\n",
      "Epoch 70/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 7.7113e-04 - val_loss: 0.0022\n",
      "Epoch 71/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 7.2208e-04 - val_loss: 0.0020\n",
      "Epoch 72/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 6.7188e-04 - val_loss: 0.0021\n",
      "Epoch 73/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 9.0085e-04 - val_loss: 0.0020\n",
      "Epoch 74/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 7.5191e-04 - val_loss: 0.0020\n",
      "Epoch 75/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 7.4618e-04 - val_loss: 0.0020\n",
      "Epoch 76/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 6.3759e-04 - val_loss: 0.0021\n",
      "Epoch 77/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 7.2131e-04 - val_loss: 0.0021\n",
      "Epoch 78/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 7.6837e-04 - val_loss: 0.0020\n",
      "Epoch 79/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 8.1936e-04 - val_loss: 0.0020\n",
      "Epoch 80/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 7.5957e-04 - val_loss: 0.0021\n",
      "Epoch 81/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 7.8587e-04 - val_loss: 0.0020\n",
      "Epoch 82/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 7.2389e-04 - val_loss: 0.0020\n",
      "Epoch 83/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 5.8360e-04 - val_loss: 0.0019\n",
      "Epoch 84/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5.0727e-04 - val_loss: 0.0021\n",
      "Epoch 85/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 6.3934e-04 - val_loss: 0.0021\n",
      "Epoch 86/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5.7020e-04 - val_loss: 0.0021\n",
      "Epoch 87/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 7.0290e-04 - val_loss: 0.0021\n",
      "Epoch 88/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 6.4313e-04 - val_loss: 0.0020\n",
      "Epoch 89/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 6.1357e-04 - val_loss: 0.0021\n",
      "Epoch 90/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5.9412e-04 - val_loss: 0.0021\n",
      "Epoch 91/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5.4864e-04 - val_loss: 0.0020\n",
      "Epoch 92/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 6.3469e-04 - val_loss: 0.0021\n",
      "Epoch 93/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5.5644e-04 - val_loss: 0.0021\n",
      "Epoch 94/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 9.1264e-04 - val_loss: 0.0021\n",
      "Epoch 95/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 6.0065e-04 - val_loss: 0.0021\n",
      "Epoch 96/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 6.1058e-04 - val_loss: 0.0021\n",
      "Epoch 97/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 6.1061e-04 - val_loss: 0.0023\n",
      "Epoch 98/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5.0809e-04 - val_loss: 0.0020\n",
      "Epoch 99/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 4.4777e-04 - val_loss: 0.0020\n",
      "Epoch 100/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 6.1999e-04 - val_loss: 0.0021\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train, epochs=100, batch_size=32, validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0022  \n",
      "Perda no conjunto de teste: 0.0021274923346936703\n"
     ]
    }
   ],
   "source": [
    "test_loss = model.evaluate(X_test, y_test)\n",
    "print(f\"Perda en el conjunto de teste: {test_loss}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step \n"
     ]
    }
   ],
   "source": [
    "predictions = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.scatter(y_test, predictions)\n",
    "plt.xlabel('Valores Reales')\n",
    "plt.ylabel('Predicciones')\n",
    "plt.title('Valores Reales vs Predicciones')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "hovertemplate": "Valores Reales=%{x}<br>Predicciones=%{y}<extra></extra>",
         "legendgroup": "",
         "marker": {
          "color": "#636efa",
          "symbol": "circle"
         },
         "mode": "markers",
         "name": "",
         "orientation": "v",
         "showlegend": false,
         "type": "scatter",
         "x": [
          0.21658986175115208,
          0.1912442396313364,
          0.09216589861751151,
          0.12442396313364054,
          0.23732718894009214,
          0.1889400921658986,
          0.10138248847926268,
          0.22811059907834103,
          0.11981566820276496,
          0.052995391705069124,
          0.06682027649769584,
          0.23963133640552997,
          0.14746543778801843,
          0.3617511520737327,
          0.3087557603686636,
          0.07834101382488479,
          0.04377880184331797,
          0.020737327188940093,
          0.347926267281106,
          0.08755760368663595,
          0.2626728110599078,
          0.12442396313364054,
          0.13824884792626727,
          0.009216589861751154,
          0.023041474654377878,
          0.08986175115207373,
          0.05069124423963133,
          0.04608294930875576,
          0.004608294930875577,
          0.2626728110599078,
          0.22119815668202764,
          0.027649769585253454,
          0.2626728110599078,
          0.2073732718894009,
          0.07834101382488479,
          0.23502304147465436,
          0.1912442396313364,
          0.20506912442396313,
          0.20506912442396313,
          0.16359447004608293,
          0.03225806451612904,
          0.11059907834101382,
          0.0184331797235023,
          0.12211981566820276,
          0.048387096774193554,
          0.1129032258064516,
          0.10138248847926268,
          0.1497695852534562,
          0.08294930875576037,
          0.055299539170506916,
          0.027649769585253454,
          0.034562211981566816,
          0.08986175115207373,
          0.059907834101382486,
          0.1935483870967742,
          0.24193548387096775,
          0.04147465437788018,
          0.016129032258064516,
          0.3433179723502304,
          0.06221198156682028,
          0.22811059907834103,
          0.25115207373271886,
          0.19815668202764977,
          0.12903225806451613,
          0.1935483870967742,
          0.2995391705069124,
          0.052995391705069124,
          0.1728110599078341,
          0.2119815668202765,
          0.4608294930875576,
          0.10138248847926268,
          0.20046082949308755,
          0.19585253456221197,
          0.10138248847926268,
          0.12211981566820276,
          0.09907834101382487,
          0.016129032258064516,
          0.33410138248847926,
          0.152073732718894,
          0.41935483870967744,
          0.21658986175115208,
          0.03225806451612904,
          0.05069124423963133,
          0.07834101382488479,
          0.03225806451612904,
          0.10829493087557604,
          0.23963133640552997,
          0.3087557603686636,
          0.06221198156682028,
          0.22811059907834103,
          0.271889400921659,
          0.3294930875576037,
          0.016129032258064516,
          0.15898617511520738,
          0.0391705069124424,
          0.07834101382488479,
          0.08294930875576037,
          0.22811059907834103,
          0.1912442396313364,
          0.034562211981566816,
          0.12442396313364054,
          0.08755760368663595,
          0.023041474654377878,
          0.08986175115207373,
          0.14746543778801843,
          0.07603686635944701,
          0.06682027649769584,
          0.07834101382488479,
          0.1705069124423963,
          0.06682027649769584,
          0.0737327188940092,
          0.009216589861751154,
          0.055299539170506916,
          0.12672811059907835,
          0.18433179723502302,
          0.04608294930875576,
          0.1705069124423963,
          0.2926267281105991,
          0.19815668202764977,
          0.1705069124423963,
          0.04377880184331797,
          0.25115207373271886,
          0.1912442396313364,
          0.055299539170506916,
          0.009216589861751154,
          0.02534562211981567,
          0.15668202764976957,
          0.07834101382488479,
          0.18433179723502302,
          0.016129032258064516,
          0.24423963133640553,
          0.3617511520737327,
          0.2857142857142857,
          0.1935483870967742,
          0.05069124423963133,
          0.21658986175115208,
          0.057603686635944694,
          0.05069124423963133,
          0.23963133640552997,
          0.0391705069124424,
          0.059907834101382486,
          0.24884792626728108,
          0.08986175115207373,
          0.07834101382488479,
          0.3387096774193548,
          0.10599078341013823,
          0.03686635944700461,
          0.07834101382488479,
          0.055299539170506916,
          0.2626728110599078,
          0.21658986175115208,
          0.2119815668202765,
          0.11981566820276496,
          0.03225806451612904,
          0.18663594470046083,
          0.21889400921658986,
          0.15898617511520738,
          0.25806451612903225,
          0.25806451612903225,
          0.048387096774193554,
          0.1129032258064516,
          0.048387096774193554,
          0.16359447004608293,
          0.05069124423963133,
          0.10138248847926268,
          0.07834101382488479,
          0.08294930875576037,
          0.2857142857142857,
          0.2880184331797235,
          0.21658986175115208,
          0.0967741935483871,
          0.15898617511520738,
          0.04608294930875576,
          0.08755760368663595,
          0.1336405529953917,
          0.03686635944700461,
          0.1912442396313364,
          0.24423963133640553,
          0.23963133640552997,
          0.1543778801843318,
          0.04377880184331797,
          0.0737327188940092,
          0.20276497695852533,
          0.07834101382488479,
          0.057603686635944694,
          0.0184331797235023,
          0.08294930875576037,
          0.23732718894009214,
          0.4009216589861751,
          0.14516129032258063,
          0.055299539170506916,
          0.15898617511520738,
          0.21658986175115208,
          0.23963133640552997,
          0.10138248847926268,
          0.057603686635944694,
          0.15668202764976957,
          0.09447004608294929,
          0.2534562211981567,
          0.20046082949308755,
          0.06682027649769584,
          0.0737327188940092,
          0.0737327188940092,
          0.055299539170506916,
          0.03686635944700461,
          0.25806451612903225,
          0.04608294930875576,
          0.3456221198156682,
          0.1728110599078341,
          0.2626728110599078,
          0.18202764976958524,
          0.02534562211981567,
          0.24193548387096775,
          0.016129032258064516,
          0.1313364055299539,
          0.24193548387096775,
          0.04608294930875576,
          0.08755760368663595,
          0.3225806451612903,
          0.2834101382488479,
          0.18202764976958524,
          0.07834101382488479,
          0.22811059907834103,
          0.2235023041474654,
          0.07834101382488479,
          0.2119815668202765,
          0.1935483870967742,
          0.3064516129032258,
          0.43317972350230416,
          0.055299539170506916,
          0.2258064516129032,
          0.35023041474654376,
          0.3087557603686636,
          0.1705069124423963,
          0.152073732718894,
          0.1129032258064516,
          0.1889400921658986,
          0.3225806451612903,
          0.04608294930875576,
          0.17972350230414746,
          0.04377880184331797,
          0.20276497695852533,
          0.24193548387096775,
          0.05069124423963133,
          0.1129032258064516,
          -0.03686635944700461,
          0.12211981566820276,
          0.26036866359447003,
          0.15898617511520738,
          0.057603686635944694,
          0.11981566820276496,
          0.07142857142857142,
          0.04377880184331797,
          0.14746543778801843,
          0.04608294930875576,
          0.1912442396313364,
          0.19815668202764977,
          0.05069124423963133,
          0.059907834101382486,
          0.4009216589861751,
          0.05069124423963133,
          0.3387096774193548,
          0.059907834101382486,
          0.25115207373271886,
          0.24423963133640553,
          0.023041474654377878,
          0.06682027649769584,
          0.03686635944700461,
          0.1912442396313364,
          0.1336405529953917,
          0.03225806451612904,
          0.06221198156682028,
          0.19815668202764977,
          0.3548387096774194,
          0.15668202764976957,
          0.08294930875576037,
          0.06451612903225806,
          0.06682027649769584,
          0.06682027649769584,
          0.06451612903225806,
          0.14516129032258063,
          0.1935483870967742,
          0.10138248847926268,
          0.24423963133640553,
          0.22119815668202764,
          0.17511520737327188,
          0.22119815668202764,
          0.06912442396313365,
          0.23732718894009214,
          0.23963133640552997,
          0.07834101382488479,
          0.2235023041474654,
          0.027649769585253454,
          0.16589861751152074,
          0.18433179723502302,
          0.01382488479262673,
          0.20276497695852533,
          0.16589861751152074,
          0.07834101382488479,
          0.04377880184331797,
          0.11059907834101382,
          0.1705069124423963,
          0.2857142857142857,
          0.09216589861751151,
          0.07603686635944701,
          0.25115207373271886,
          0.059907834101382486,
          0.17972350230414746,
          0.08294930875576037,
          0.03225806451612904,
          0.25115207373271886,
          0.06682027649769584,
          0.055299539170506916,
          0.08294930875576037,
          0.04377880184331797,
          0.04147465437788018,
          0.09447004608294929,
          0.21889400921658986,
          0.009216589861751154,
          0.18433179723502302,
          0.21658986175115208,
          0.1912442396313364,
          0.07142857142857142,
          0.06451612903225806,
          0.03686635944700461,
          0.04608294930875576,
          0.17741935483870966,
          0.04377880184331797,
          0.1889400921658986,
          0.18663594470046083,
          0.20046082949308755,
          0.2096774193548387,
          0.10138248847926268,
          0.04608294930875576,
          0.5046082949308757,
          0.11751152073732718,
          0.057603686635944694,
          0.1543778801843318,
          0.016129032258064516,
          0.08294930875576037,
          0.11059907834101382,
          0.2119815668202765,
          0.2995391705069124,
          0.1705069124423963,
          0.10138248847926268,
          0.16359447004608293,
          0.07603686635944701,
          0.07142857142857142,
          0.41244239631336405,
          0.08986175115207373,
          0.08755760368663595,
          0.11751152073732718,
          0.21658986175115208,
          0.055299539170506916,
          0.06682027649769584,
          0.07834101382488479,
          0.3064516129032258,
          0.02534562211981567,
          0.12442396313364054,
          0.1336405529953917,
          0.23732718894009214,
          0.04377880184331797,
          0.02534562211981567,
          0.07142857142857142,
          0.052995391705069124,
          0.07603686635944701,
          0.1705069124423963,
          0.023041474654377878,
          0.0737327188940092,
          0.029953917050691246,
          0.17511520737327188,
          0.27419354838709675,
          0.048387096774193554,
          0.07834101382488479,
          0.3433179723502304,
          0.15898617511520738,
          0.4170506912442396,
          0.08986175115207373,
          0.24423963133640553,
          0.3018433179723502,
          0.006912442396313362,
          0.20046082949308755,
          0.27649769585253453,
          0.27649769585253453,
          0.1336405529953917,
          0.1152073732718894,
          0.08294930875576037,
          0.23963133640552997,
          0.04147465437788018,
          0.32027649769585254,
          0.11981566820276496,
          0.18202764976958524,
          0.16129032258064516,
          0.16359447004608293,
          0.02534562211981567,
          0.2073732718894009,
          0.07142857142857142,
          0.17741935483870966,
          0.1705069124423963,
          0.16359447004608293,
          0.07142857142857142,
          0.034562211981566816,
          0.07603686635944701,
          0.2142857142857143,
          0.1705069124423963,
          0.12442396313364054,
          0.055299539170506916,
          0.0391705069124424,
          0.21658986175115208,
          0.048387096774193554,
          0.07834101382488479,
          0.07834101382488479,
          0.09216589861751151,
          0.06912442396313365,
          0.26036866359447003,
          0.055299539170506916,
          0.07834101382488479,
          0.04377880184331797,
          0.22811059907834103,
          0.10829493087557604,
          0.18202764976958524,
          0.0391705069124424,
          0.08294930875576037,
          0.25806451612903225,
          0.016129032258064516,
          0.06682027649769584,
          0.06682027649769584,
          0.07142857142857142,
          0.1359447004608295,
          0.07142857142857142,
          0.12442396313364054,
          0.08986175115207373,
          0.4400921658986175,
          0.04377880184331797,
          0.10829493087557604,
          0.22811059907834103,
          0.2857142857142857,
          0.2258064516129032,
          0.1705069124423963,
          0.07834101382488479,
          0.1728110599078341,
          0.059907834101382486,
          0.06682027649769584,
          0.14285714285714285,
          0.10368663594470046,
          0.14285714285714285,
          0.055299539170506916,
          0.059907834101382486,
          0.055299539170506916,
          0.1935483870967742,
          0.1935483870967742,
          0.1935483870967742,
          0.3686635944700461,
          0.08064516129032259,
          0.06682027649769584,
          0.1705069124423963,
          0.05069124423963133,
          0.19585253456221197,
          0.22119815668202764,
          0.12442396313364054,
          0.3410138248847926,
          0.1152073732718894,
          0.19815668202764977,
          0.1129032258064516,
          0.04377880184331797,
          0.18663594470046083,
          0.12442396313364054,
          0.1497695852534562,
          0.1935483870967742,
          0.10138248847926268,
          0.01382488479262673,
          0.25115207373271886,
          0.0391705069124424,
          0.22811059907834103,
          0.19815668202764977,
          0.07834101382488479,
          0.1129032258064516,
          0.271889400921659,
          0.152073732718894,
          0.06221198156682028,
          0.0391705069124424,
          0.08986175115207373,
          0.0737327188940092,
          0.2626728110599078,
          0.11059907834101382,
          0.14746543778801843,
          0.0391705069124424,
          0.3456221198156682,
          0.1543778801843318,
          0.10138248847926268,
          0.12442396313364054,
          0.25115207373271886,
          0.1336405529953917,
          0.2995391705069124,
          0.41244239631336405,
          0.04147465437788018,
          0.02534562211981567,
          0.07834101382488479,
          0.10138248847926268,
          0.16129032258064516
         ],
         "xaxis": "x",
         "y": [
          0.33919867873191833,
          0.21301865577697754,
          0.18910932540893555,
          0.24891003966331482,
          0.25135061144828796,
          0.19706225395202637,
          0.08434534072875977,
          0.2570633590221405,
          0.15102916955947876,
          0.09210562705993652,
          0.09842489659786224,
          0.2558196187019348,
          0.2248629331588745,
          0.2402491569519043,
          0.3228748142719269,
          0.08460162580013275,
          0.05215907469391823,
          0.05146476626396179,
          0.23390114307403564,
          0.091265469789505,
          0.2844206392765045,
          0.1268698126077652,
          0.13190479576587677,
          -0.0035264454782009125,
          0.02378413826227188,
          0.08746089786291122,
          0.045997098088264465,
          0.05554091930389404,
          0.011807570233941078,
          0.2844206392765045,
          0.3054458796977997,
          0.018357325345277786,
          0.2428373396396637,
          0.20478031039237976,
          0.08077573776245117,
          0.23505577445030212,
          0.2687130570411682,
          0.15195700526237488,
          0.22878369688987732,
          0.15522025525569916,
          0.042135901749134064,
          0.047810062766075134,
          0.017383258789777756,
          0.15882298350334167,
          0.04836498945951462,
          0.13541199266910553,
          0.086105577647686,
          0.212049663066864,
          0.07465142011642456,
          0.0795392096042633,
          0.016612332314252853,
          0.06517256796360016,
          0.0906020998954773,
          0.062139466404914856,
          0.21080635488033295,
          0.1958269476890564,
          0.06144929304718971,
          0.046779803931713104,
          0.3904668986797333,
          0.07385663688182831,
          0.24367579817771912,
          0.24994756281375885,
          0.2499673217535019,
          0.19201016426086426,
          0.15479087829589844,
          0.3073471486568451,
          0.06471198797225952,
          0.19171664118766785,
          0.18199658393859863,
          0.41545718908309937,
          0.18341746926307678,
          0.2200041562318802,
          0.18146167695522308,
          0.18341746926307678,
          0.33003029227256775,
          0.11777439713478088,
          0.015598621219396591,
          0.33887147903442383,
          0.14705297350883484,
          0.2606973350048065,
          0.21743881702423096,
          0.046669792383909225,
          0.058496300131082535,
          0.08646248281002045,
          0.08842580765485764,
          0.1738826036453247,
          0.1804388016462326,
          0.300285667181015,
          0.07029448449611664,
          0.17980623245239258,
          0.3312864601612091,
          0.3178558051586151,
          0.0632825642824173,
          0.15848124027252197,
          0.03280171751976013,
          0.1204247921705246,
          0.2304501235485077,
          0.23558466136455536,
          0.22312436997890472,
          0.04345889389514923,
          0.1268698126077652,
          0.08404303342103958,
          0.02378413826227188,
          0.08269599080085754,
          0.14469830691814423,
          0.07398425787687302,
          0.08358258008956909,
          0.08646248281002045,
          0.258313924074173,
          0.08358258008956909,
          0.08802586793899536,
          0.05211092531681061,
          0.10993152856826782,
          0.15481062233448029,
          0.22874969244003296,
          0.048675570636987686,
          0.1974181830883026,
          0.28845110535621643,
          0.2212560474872589,
          0.1974187046289444,
          0.05174997076392174,
          0.2795855402946472,
          0.21301865577697754,
          0.0795392096042633,
          0.017886582762002945,
          0.041505370289087296,
          0.1962313950061798,
          0.07997496426105499,
          0.16697488725185394,
          0.03609151393175125,
          0.22435368597507477,
          0.2402491569519043,
          0.17714017629623413,
          0.21264125406742096,
          0.07833605259656906,
          0.21765169501304626,
          0.0632697269320488,
          0.05819237232208252,
          0.3470154106616974,
          0.03280177339911461,
          0.09331086277961731,
          0.23602110147476196,
          0.08987793326377869,
          0.0897165834903717,
          0.2465214729309082,
          0.14374209940433502,
          0.04849957674741745,
          0.06958141177892685,
          0.07734696567058563,
          0.3184480369091034,
          0.22786279022693634,
          0.19034425914287567,
          0.08764885365962982,
          0.07869243621826172,
          0.23212602734565735,
          0.2296762317419052,
          0.2086692750453949,
          0.29497626423835754,
          0.2516859471797943,
          0.038562797009944916,
          0.13541199266910553,
          0.04836498945951462,
          0.1892065703868866,
          0.046829789876937866,
          0.10428529977798462,
          0.06241288408637047,
          0.10006816685199738,
          0.23701323568820953,
          0.2586047947406769,
          0.23240934312343597,
          0.11890654265880585,
          0.11854639649391174,
          0.03787057846784592,
          0.1546068787574768,
          0.14560769498348236,
          0.047245219349861145,
          0.18759685754776,
          0.10805633664131165,
          0.30455297231674194,
          0.10408170521259308,
          0.06311936676502228,
          0.07041095942258835,
          0.12340050935745239,
          0.07786808907985687,
          0.06484329700469971,
          0.03657129034399986,
          0.06252692639827728,
          0.3115399181842804,
          0.3191826045513153,
          0.22186179459095,
          0.06385849416255951,
          0.15179142355918884,
          0.22786279022693634,
          0.22690920531749725,
          0.08675085008144379,
          0.06117844581604004,
          0.14123781025409698,
          0.07200577110052109,
          0.1294412910938263,
          0.1923222541809082,
          0.06354669481515884,
          0.06193355470895767,
          0.09512802958488464,
          0.06354323029518127,
          0.0414065346121788,
          0.2516859769821167,
          0.05032849311828613,
          0.25807079672813416,
          0.19133521616458893,
          0.23782353103160858,
          0.17147067189216614,
          0.024888277053833008,
          0.21309466660022736,
          0.0632825642824173,
          0.17936694622039795,
          0.17597557604312897,
          0.04612988233566284,
          0.06438416242599487,
          0.31202414631843567,
          0.2975247800350189,
          0.18536114692687988,
          0.057897862046957016,
          0.23290076851844788,
          0.2152950018644333,
          0.08287747204303741,
          0.18199658393859863,
          0.2917633652687073,
          0.1612669974565506,
          0.3470532298088074,
          0.07157491892576218,
          0.1314232349395752,
          0.3906364142894745,
          0.24786162376403809,
          0.1815911829471588,
          0.2015506625175476,
          0.12712937593460083,
          0.20764757692813873,
          0.2670641839504242,
          0.05613681674003601,
          0.226218581199646,
          0.05751348286867142,
          0.20787730813026428,
          0.1993514448404312,
          0.05218468979001045,
          0.05181271582841873,
          0.06580333411693573,
          0.15882298350334167,
          0.20864297449588776,
          0.19124791026115417,
          0.06451290845870972,
          0.08764885365962982,
          0.07580135762691498,
          0.05751348286867142,
          0.1419183760881424,
          0.03672836348414421,
          0.23606880009174347,
          0.19767813384532928,
          0.05218468979001045,
          0.08130170404911041,
          0.2518344521522522,
          0.07942649722099304,
          0.26505500078201294,
          0.062139466404914856,
          0.25036177039146423,
          0.08738663792610168,
          0.030413668602705002,
          0.06466898322105408,
          0.0672713965177536,
          0.27506569027900696,
          0.17993749678134918,
          0.07869243621826172,
          0.07159706950187683,
          0.42565616965293884,
          0.32815876603126526,
          0.1920529007911682,
          0.04225752502679825,
          0.06979835033416748,
          0.062094900757074356,
          0.08538935333490372,
          0.06340271234512329,
          0.15098443627357483,
          0.24954622983932495,
          0.08675085008144379,
          0.17908769845962524,
          0.24013905227184296,
          0.17957153916358948,
          0.2521393299102783,
          0.07020632922649384,
          0.22759515047073364,
          0.3219701945781708,
          0.06748349964618683,
          0.22430898249149323,
          0.018357310444116592,
          0.20570701360702515,
          0.1856432855129242,
          0.016741514205932617,
          0.2703342139720917,
          0.20570701360702515,
          0.07101225852966309,
          0.05174997076392174,
          0.16696380078792572,
          0.12183628976345062,
          0.19630348682403564,
          0.08217240869998932,
          0.07579910755157471,
          0.2795855402946472,
          0.03827884420752525,
          0.1839762032032013,
          0.06778791546821594,
          0.06889840960502625,
          0.2840678095817566,
          0.06688831001520157,
          0.07734696567058563,
          0.04225752502679825,
          0.041699185967445374,
          0.049514271318912506,
          0.09284090995788574,
          0.22745776176452637,
          -0.0035264454782009125,
          0.19592612981796265,
          0.2544933259487152,
          0.21427322924137115,
          0.08922630548477173,
          0.08500649034976959,
          0.05012058839201927,
          0.056604377925395966,
          0.25190287828445435,
          0.04820036515593529,
          0.21242189407348633,
          0.2134406715631485,
          0.2030077874660492,
          0.2506248652935028,
          0.15930406749248505,
          0.07579542696475983,
          0.32107609510421753,
          0.13345646858215332,
          0.06451290845870972,
          0.21628037095069885,
          0.02335755154490471,
          0.07019305974245071,
          0.09196974337100983,
          0.18199658393859863,
          0.28517234325408936,
          0.24128806591033936,
          0.25891703367233276,
          0.21241575479507446,
          0.07745915651321411,
          0.07580135762691498,
          0.2028253972530365,
          0.10736823081970215,
          0.0869666337966919,
          0.10557544231414795,
          0.19935964047908783,
          0.06059420481324196,
          0.08111482858657837,
          0.10389435291290283,
          0.27557453513145447,
          0.01979885622859001,
          0.1268698126077652,
          0.15405839681625366,
          0.21379896998405457,
          0.017977014183998108,
          0.03212359547615051,
          0.07580135762691498,
          0.07204502820968628,
          0.07579910755157471,
          0.24128806591033936,
          0.030413668602705002,
          0.08039352297782898,
          0.03217694163322449,
          0.18594637513160706,
          0.21719768643379211,
          0.04033100977540016,
          0.050449296832084656,
          0.267988920211792,
          0.19766339659690857,
          0.42271676659584045,
          0.05652526393532753,
          0.22341874241828918,
          0.2596258819103241,
          0.011807570233941078,
          0.22383612394332886,
          0.17311891913414001,
          0.30126479268074036,
          0.14560769498348236,
          0.12802161276340485,
          0.07526542246341705,
          0.32233306765556335,
          0.06382142007350922,
          0.1334051489830017,
          0.08764885365962982,
          0.1805940568447113,
          0.2254558503627777,
          0.07239080965518951,
          0.024888277053833008,
          0.20450812578201294,
          0.0523616299033165,
          0.20597858726978302,
          0.14375118911266327,
          0.1892065703868866,
          0.07561857998371124,
          0.039150334894657135,
          0.07398425787687302,
          0.18762968480587006,
          0.18503133952617645,
          0.08849145472049713,
          0.0638585016131401,
          0.05037920922040939,
          0.18615451455116272,
          0.04579314589500427,
          0.10933403670787811,
          0.10933403670787811,
          0.059782952070236206,
          0.07020630687475204,
          0.25856801867485046,
          0.06631787121295929,
          0.06315518170595169,
          0.06750506162643433,
          0.23558466136455536,
          0.09374891221523285,
          0.2618250250816345,
          0.05909731611609459,
          0.07626484334468842,
          0.25679418444633484,
          0.0632825642824173,
          0.11093984544277191,
          0.173850417137146,
          0.08498515188694,
          0.13355152308940887,
          0.06848238408565521,
          0.1490962952375412,
          0.058546461164951324,
          0.3925130069255829,
          0.06311936676502228,
          0.1738826036453247,
          0.23558466136455536,
          0.19630348682403564,
          0.23869812488555908,
          0.16967405378818512,
          0.07127314805984497,
          0.17641539871692657,
          0.059159889817237854,
          0.06629679352045059,
          0.13550560176372528,
          0.08589176088571548,
          0.11634555459022522,
          0.09947489202022552,
          0.05284859612584114,
          0.07947168499231339,
          0.20764651894569397,
          0.2917633652687073,
          0.20571355521678925,
          0.27762359380722046,
          0.07335610687732697,
          0.09842489659786224,
          0.1971319168806076,
          0.050043825060129166,
          0.24143701791763306,
          0.26743167638778687,
          0.09643471240997314,
          0.30671700835227966,
          0.17683960497379303,
          0.19735075533390045,
          0.06390437483787537,
          0.0486653633415699,
          0.23042097687721252,
          0.13102057576179504,
          0.15699440240859985,
          0.20298728346824646,
          0.07789675891399384,
          0.016741514205932617,
          0.24662086367607117,
          0.08746004849672318,
          0.23558466136455536,
          0.1778128445148468,
          0.06315518170595169,
          0.06323297321796417,
          0.23084914684295654,
          0.14705295860767365,
          0.07029451429843903,
          0.04952378198504448,
          0.09817254543304443,
          0.08039352297782898,
          0.3785199820995331,
          0.09196974337100983,
          0.11870843172073364,
          0.03280177339911461,
          0.3535303473472595,
          0.21628037095069885,
          0.17837634682655334,
          0.0701766163110733,
          0.2589212954044342,
          0.21514736115932465,
          0.28517234325408936,
          0.3044799864292145,
          0.07472021877765656,
          0.024888277053833008,
          0.08530861884355545,
          0.08610562235116959,
          0.17192387580871582
         ],
         "yaxis": "y"
        }
       ],
       "layout": {
        "legend": {
         "tracegroupgap": 0
        },
        "shapes": [
         {
          "line": {
           "color": "red",
           "dash": "dot"
          },
          "type": "line",
          "x0": -0.03686635944700461,
          "x1": 0.5046082949308757,
          "y0": -0.03686635944700461,
          "y1": 0.5046082949308757
         }
        ],
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "white",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "white",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "#C8D4E3",
             "linecolor": "#C8D4E3",
             "minorgridcolor": "#C8D4E3",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "#C8D4E3",
             "linecolor": "#C8D4E3",
             "minorgridcolor": "#C8D4E3",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "white",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "#C8D4E3"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "white",
          "polar": {
           "angularaxis": {
            "gridcolor": "#EBF0F8",
            "linecolor": "#EBF0F8",
            "ticks": ""
           },
           "bgcolor": "white",
           "radialaxis": {
            "gridcolor": "#EBF0F8",
            "linecolor": "#EBF0F8",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "white",
            "gridcolor": "#DFE8F3",
            "gridwidth": 2,
            "linecolor": "#EBF0F8",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "#EBF0F8"
           },
           "yaxis": {
            "backgroundcolor": "white",
            "gridcolor": "#DFE8F3",
            "gridwidth": 2,
            "linecolor": "#EBF0F8",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "#EBF0F8"
           },
           "zaxis": {
            "backgroundcolor": "white",
            "gridcolor": "#DFE8F3",
            "gridwidth": 2,
            "linecolor": "#EBF0F8",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "#EBF0F8"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "#DFE8F3",
            "linecolor": "#A2B1C6",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "#DFE8F3",
            "linecolor": "#A2B1C6",
            "ticks": ""
           },
           "bgcolor": "white",
           "caxis": {
            "gridcolor": "#DFE8F3",
            "linecolor": "#A2B1C6",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "#EBF0F8",
           "linecolor": "#EBF0F8",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "#EBF0F8",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "#EBF0F8",
           "linecolor": "#EBF0F8",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "#EBF0F8",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "text": "Valores Reales vs Predicciones"
        },
        "xaxis": {
         "anchor": "y",
         "domain": [
          0,
          1
         ],
         "title": {
          "text": "Valores Reales"
         }
        },
        "yaxis": {
         "anchor": "x",
         "domain": [
          0,
          1
         ],
         "title": {
          "text": "Predicciones"
         }
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import plotly.express as px\n",
    "\n",
    "# Graficar el resultado del entrenamiento del modelo usando plotly\n",
    "resultados_df = pd.DataFrame({\n",
    "    \"Valores Reales\": y_test,\n",
    "    \"Predicciones\": predictions.ravel() # predictions tiene 2D, ravel para transformar en 1D para la creación del df\n",
    "})\n",
    "\n",
    "fig = px.scatter(\n",
    "    resultados_df,\n",
    "    x=\"Valores Reales\",\n",
    "    y=\"Predicciones\",\n",
    "    title=\"Valores Reales vs Predicciones\",\n",
    "    template=\"plotly_white\"\n",
    ")\n",
    "\n",
    "# Añadir una línea de referencia donde las predicciones coinciden perfectamente con los valores reales\n",
    "fig.add_shape(\n",
    "    type=\"line\",\n",
    "    x0=resultados_df[\"Valores Reales\"].min(),\n",
    "    y0=resultados_df[\"Valores Reales\"].min(),\n",
    "    x1=resultados_df[\"Valores Reales\"].max(),\n",
    "    y1=resultados_df[\"Valores Reales\"].max(),\n",
    "    line=dict(color=\"red\", dash=\"dot\")\n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
