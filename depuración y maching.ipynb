{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Escaladores\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Train, Test\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Modelos\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "\n",
    "# Métricas\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('C:/Users/peni_/Desktop/proyecto/Proyecto-Final-Bootcamp---Dream-Team/data/df_to_encode.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "He hecho el onehot el knn el mapa de corr, feature importance, y buscar el mejor r2 falta que todo este en archivos pickel, porque queria que le dierais el visto bueno."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_encoded = df.copy()\n",
    "\n",
    "encoder = OneHotEncoder(sparse_output=False, drop='first')\n",
    "encoded_features = encoder.fit_transform(df_encoded[['property_types']])\n",
    "# Verifica el número de características generadas\n",
    "feature_names = encoder.get_feature_names_out()\n",
    "print(f'Number of feature names: {len(feature_names)}')\n",
    "print(f'Number of encoded features: {encoded_features.shape[1]}')\n",
    "\n",
    "# Crear el DataFrame con las características codificadas\n",
    "encoded_df = pd.DataFrame(encoded_features, columns=feature_names)                                        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "He cambiado los nombres para que sea mas fácil para nosotros."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_df = encoded_df.rename(columns={'property_types_Habitación': 'habitacion'})\n",
    "encoded_df = encoded_df.rename(columns={'property_types_otro': 'alojamiento entero'})\n",
    "encoded_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lo uno todo a nuestro df principal y dropeo la que nos sobra también cambio a int64 (lo he tenido que poner asi porque se cambiaba a int32 cosa que no me habia pasado antes creo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_encoded = pd.concat([df_encoded, encoded_df], axis=1)\n",
    "df_encoded.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_encoded = df_encoded.drop('property_types',axis= 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_encoded['habitacion'] = df_encoded['habitacion'].astype('int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_encoded['alojamiento entero'] = df_encoded['alojamiento entero'].astype('int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_encoded.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "KNNImputer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "imputer = KNNImputer(n_neighbors=3)\n",
    "df_encoded = pd.DataFrame(imputer.fit_transform(df_encoded), columns=df_encoded.columns)\n",
    "df_encoded"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creamos una copia de nuestro df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_encoded.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(30, 20))\n",
    "\n",
    "sns.heatmap(data = df_encoded.corr(), annot = True,cmap=\"Blues\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feature Importance se observa que los servicios tienen algo que ver con los precios."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# Feature Importance\n",
    "\n",
    "# Modelo de RandomForest para obtener Feature Importance\n",
    "model = RandomForestRegressor(n_estimators = 250,\n",
    "                               random_state = 0)\n",
    "# Entrenamos el modelo\n",
    "model.fit(df.drop([\"prices_per_night\"], axis = 1), df[\"prices_per_night\"])\n",
    "\n",
    "# Calculamos Feature Importance\n",
    "importances = model.feature_importances_\n",
    "\n",
    "df = pd.DataFrame(data = zip(df.drop([\"prices_per_night\"], axis = 1).columns, importances),\n",
    "                              columns = [\"Columnas\", \"Importancia\"])\n",
    "\n",
    "df = df.sort_values(\"Importancia\", ascending = False)\n",
    "\n",
    "print(\"Feature Importance:\")\n",
    "\n",
    "for index, (feature, importance) in enumerate(df.values):\n",
    "    \n",
    "    print(f\"{index + 1:2}. feature {index:2} ({importance:20}): {feature}\")\n",
    "\n",
    "plt.figure(figsize = (12, 8))\n",
    "\n",
    "plt.title(\"Feature Importances\")\n",
    "sns.barplot(x = df[\"Importancia\"], y = df[\"Columnas\"], palette = sns.color_palette(\"husl\", 17))\n",
    "\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TRAIN TEST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_encoded.drop(\"prices_per_night\", axis = 1)\n",
    "y = df_encoded[\"prices_per_night\"]\n",
    "print(X.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 42)\n",
    "\n",
    "print(f\"X_train: {X_train.shape}, y_train: {y_train.shape}\")\n",
    "print(f\"X_test: {X_test.shape}, y_test: {y_test.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Escalado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_scaler = MinMaxScaler()\n",
    "X_train = x_scaler.fit_transform(X_train)\n",
    "X_test = x_scaler.transform(X_test)\n",
    "\n",
    "y_scaler = MinMaxScaler()\n",
    "y_train = y_scaler.fit_transform(np.array(y_train).reshape(-1, 1))\n",
    "y_test = y_scaler.transform(np.array(y_test).reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Buscar el mejor modelo copn el r2 mas alto "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {\"Linear Regression\": LinearRegression(),\n",
    "    \"Random Forest\": RandomForestRegressor(random_state=42),\n",
    "    \"Support Vector Regressor\": SVR()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resultados_lista = []\n",
    "\n",
    "for model_name, model in models.items():\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    y_hat = model.predict(X_test)\n",
    "    \n",
    "    y_test_inv = y_scaler.inverse_transform(y_test.reshape(-1, 1)).ravel()\n",
    "    y_hat_inv = y_scaler.inverse_transform(y_hat.reshape(-1, 1)).ravel()\n",
    "    \n",
    "    mae = mean_absolute_error(y_test_inv, y_hat_inv)\n",
    "    mse = mean_squared_error(y_test_inv, y_hat_inv)\n",
    "    r2 = r2_score(y_test_inv, y_hat_inv)\n",
    "    \n",
    "    resultados_lista.append({\"model_name\": model_name,\"mae\": mae,\"mse\": mse,\"r2_score\": r2})\n",
    "resultados = pd.DataFrame(resultados_lista)\n",
    "resultados = resultados.sort_values(by=\"r2_score\", ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
